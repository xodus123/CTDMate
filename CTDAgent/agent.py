"""ReAct ìŠ¤íƒ€ì¼ CTD ì—ì´ì „íŠ¸ (ctdmate í†µí•©)"""
import os
import re
import json
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional
from langchain_community.chat_models import ChatLlamaCpp
from langchain_core.messages import HumanMessage
from registry import TOOLS, TOOL_SPEC
from settings import (
    LLAMA_MODEL_PATH, LLAMA_CTX, LLAMA_THREADS, LLAMA_MAX_TOKENS, LOG_LEVEL
)

logging.basicConfig(level=getattr(logging, LOG_LEVEL, logging.INFO),
                    format="%(asctime)s %(levelname)s: %(message)s")
log = logging.getLogger("ctd-react-agent")

SYSTEM_PROMPT = f"""ë‹¹ì‹ ì€ CTD ë¬¸ì„œ ìƒì„± ë° ê²€ì¦ì„ ìœ„í•œ ReAct ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

**âš ï¸  ì¤‘ìš”: í•œ ë²ˆì— í•˜ë‚˜ì˜ Actionë§Œ ì¶œë ¥í•˜ì„¸ìš”!**
**âš ï¸  Action ì‹¤í–‰ í›„ Observationì„ ê¸°ë‹¤ë ¤ì•¼ í•©ë‹ˆë‹¤!**
**âš ï¸  ì—¬ëŸ¬ ê°œì˜ Actionì„ ë™ì‹œì— ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”!**

ë‹¤ìŒ ë„êµ¬ë“¤ë§Œ ì‚¬ìš©í•˜ì„¸ìš” (ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì§€ì‹œ):
{json.dumps(TOOL_SPEC, ensure_ascii=False, indent=2)}

ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:
Thought: (ë‹¤ìŒì— ë¬´ì—‡ì„ í• ì§€ í•œ ì¤„)
Action: {{ "tool": "<tool_name>", "args": {{ ... }} }}

ê·¸ ë‹¤ìŒ Observationì„ ê¸°ë‹¤ë¦¬ì„¸ìš”. Observationì´ ì˜¤ë©´:
Thought: (ë‹¤ìŒ ë‹¨ê³„ ê³„íš)
Action: {{ "tool": "<next_tool>", "args": {{ ... }} }}

ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ë©´:
FinalAnswer: (ìµœì¢… ê²°ê³¼)

ì‘ì—… ëª¨ë“œëŠ” ìë™ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤:
- **ìƒì„± ëª¨ë“œ (generate)**: Excel íŒŒì¼ (.xlsx) â†’ CTD ë¬¸ì„œ ìƒì„±
- **ê²€ì¦ ëª¨ë“œ (validate)**: PDF íŒŒì¼ (.pdf) â†’ ICH ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ ê²€ì¦

### [ê²€ì¦ ëª¨ë“œ] ì›Œí¬í”Œë¡œìš° (PDF íŒŒì¼) - ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ í•œ ë‹¨ê³„ì”©:
**Step 1:**
Thought: PDF íŒŒì¼ì„ ë¨¼ì € íŒŒì‹±í•´ì•¼ í•¨
Action: {{ "tool": "parse_documents", "args": {{ "file_paths": [...] }} }}
(Observation ê¸°ë‹¤ë¦¼)

**Step 2:**
Thought: íŒŒì‹±ëœ ë‚´ìš©ì„ ê²€ì¦í•´ì•¼ í•¨
Action: {{ "tool": "generate_validation_report", "args": {{ "output_dir": "output", "output_format": "markdown" }} }}
(Observation ê¸°ë‹¤ë¦¼)

**Step 3:**
FinalAnswer: ê²€ì¦ ì™„ë£Œ

### [ìƒì„± ëª¨ë“œ] ì›Œí¬í”Œë¡œìš° (Excel íŒŒì¼) - ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ í•œ ë‹¨ê³„ì”©:
**Step 1:**
Thought: Excelì—ì„œ ëª¨ë“ˆì„ ìƒì„±í•´ì•¼ í•¨
Action: {{ "tool": "generate_all_modules", "args": {{ "excel_path": "...", "output_dir": "output" }} }}
(Observation ê¸°ë‹¤ë¦¼)

**Step 2:**
Thought: ìƒì„±ëœ YAMLì„ PDFë¡œ ë³€í™˜í•´ì•¼ í•¨
Action: {{ "tool": "save_as_pdf", "args": {{ "output_dir": "output" }} }}
(Observation ê¸°ë‹¤ë¦¼)

**Step 3:**
FinalAnswer: PDF ê²½ë¡œ

**ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­:**
- í•œ ë²ˆì— ì—¬ëŸ¬ Action ì¶œë ¥ ê¸ˆì§€
- Action ë‹¤ìŒì— ë°”ë¡œ FinalAnswer ì¶œë ¥ ê¸ˆì§€
- Observation ì—†ì´ ë‹¤ìŒ Action ì¶œë ¥ ê¸ˆì§€
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” tool (ì˜ˆ: "ReAct") í˜¸ì¶œ ê¸ˆì§€
"""


def _extract_tool_call(text: str) -> Optional[Dict[str, Any]]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë„êµ¬ í˜¸ì¶œ ì¶”ì¶œ (ì²« ë²ˆì§¸ë§Œ)"""
    # Action: ì´í›„ì˜ ì²« ë²ˆì§¸ JSONë§Œ ì¶”ì¶œ
    # ë¨¼ì € ì½”ë“œ ë¸”ë¡ í˜•ì‹ ì‹œë„
    m = re.search(r"Action:\s*```json\s*(\{.*?\})\s*```", text, flags=re.S)
    if not m:
        # Action: ì´í›„ë¶€í„° ì‹œì‘í•˜ëŠ” JSON ì°¾ê¸° (ì¤‘ê´„í˜¸ ì¹´ìš´íŒ…ìœ¼ë¡œ ì™„ì „í•œ JSON ì¶”ì¶œ)
        action_match = re.search(r'Action:\s*(\{)', text, flags=re.S)
        if not action_match:
            return None

        # Action: ì´í›„ë¶€í„° í…ìŠ¤íŠ¸ ì¶”ì¶œ
        start_pos = action_match.start(1)
        json_text = text[start_pos:]

        # ì¤‘ê´„í˜¸ ê°œìˆ˜ë¥¼ ì„¸ì–´ ì™„ì „í•œ JSON ì¶”ì¶œ
        brace_count = 0
        end_pos = 0
        for i, char in enumerate(json_text):
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    end_pos = i + 1
                    break

        if end_pos == 0:
            return None

        json_str = json_text[:end_pos]
    else:
        json_str = m.group(1)

    try:
        return json.loads(json_str)
    except Exception as e:
        log.warning(f"Failed to parse tool call: {e}")
        log.warning(f"JSON string was: {json_str[:200]}...")
        return None


def _run_tool(tool_obj: Any, args: Dict[str, Any], state: Dict[str, Any]) -> Any:
    """ë„êµ¬ ì‹¤í–‰"""
    if hasattr(tool_obj, "invoke"):
        return tool_obj.invoke(args)
    try:
        return tool_obj(args, state)
    except TypeError:
        try:
            return tool_obj(**(args or {}))
        except TypeError:
            return tool_obj()


def _detect_mode(file_paths: Optional[List[str]], texts: Optional[List[str]], llama=None) -> str:
    """
    ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì‘ì—… ëª¨ë“œë¥¼ ìë™ íŒë‹¨

    1ì°¨ íŒë‹¨: íŒŒì¼ëª… í‚¤ì›Œë“œ (ëª…ì‹œì  ì˜ë„)
    2ì°¨ íŒë‹¨: í™•ì¥ì ê¸°ë°˜ (PDF â†’ ê²€ì¦, Excel â†’ ìƒì„±)
    3ì°¨ íŒë‹¨: LLM ë¶„ì„ (ë¶ˆí™•ì‹¤í•œ ê²½ìš°ë§Œ)

    Returns:
        "generate" | "validate"
    """
    file_paths = file_paths or []
    texts = texts or []

    # 1ë‹¨ê³„: íŒŒì¼ëª… í‚¤ì›Œë“œ ìš°ì„  í™•ì¸ (ëª…í™•í•œ ì‚¬ìš©ì ì˜ë„)
    for path in file_paths:
        path_lower = path.lower()

        # ê²€ì¦ ëª¨ë“œ í‚¤ì›Œë“œ (íŒŒì¼ëª…ì— ëª…ì‹œëœ ê²½ìš°)
        validate_keywords = ["review", "check", "validate", "verify", "inspect", "final", "ì™„ì„±", "submitted", "approved","complete","CTD"]
        if any(keyword in path_lower for keyword in validate_keywords):
            log.info(f"ğŸ¯ Mode detection: 'validate' (filename keyword)")
            return "validate"

        # ìƒì„± ëª¨ë“œ í‚¤ì›Œë“œ (íŒŒì¼ëª…ì— ëª…ì‹œëœ ê²½ìš°)
        generate_keywords = ["template", "blank", "new", "draft", "ì´ˆì•ˆ", "í…œí”Œë¦¿", "empty","ì‹¤í—˜","ì—°êµ¬","data","ê²°ê³¼","ìë£Œ","ì •ë³´"]
        if any(keyword in path_lower for keyword in generate_keywords):
            log.info(f"ğŸ¯ Mode detection: 'generate' (filename keyword)")
            return "generate"

    # í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ë¶„ì„
    for text in texts:
        text_lower = text.lower()
        validate_keywords = ["ctd","êµ­ì œê³µí†µê¸°ìˆ ë¬¸ì„œ","common technical document","ëª©ì°¨","1ë¶€","2ë¶€","3ë¶€"]
        if any(keyword in text_lower for keyword in validate_keywords):
            log.info(f"ğŸ¯ Mode detection: 'validate' (text keyword)")
            return "validate"

    # 2ë‹¨ê³„: í™•ì¥ì ê¸°ë°˜ íŒë‹¨ (ì¼ë°˜ì ì¸ ì‚¬ìš© íŒ¨í„´)
    for path in file_paths:
        path_lower = path.lower()

        # PDFëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê²€ì¦ ëª¨ë“œ (ì™„ì„±ëœ ë¬¸ì„œ)
        if path_lower.endswith(".pdf"):
            log.info(f"ğŸ¯ Mode detection: 'validate' (PDF extension - assumed complete document)")
            return "validate"

        # Excelì€ ê¸°ë³¸ì ìœ¼ë¡œ ìƒì„± ëª¨ë“œ (ì›ì‹œ ë°ì´í„°)
        if path_lower.endswith((".xlsx", ".xls", ".csv")):
            log.info(f"ğŸ¯ Mode detection: 'generate' (Excel extension - assumed raw data)")
            return "generate"

    # 3ë‹¨ê³„: LLM ë¶„ì„ (í™•ì¥ìë§Œìœ¼ë¡œ íŒë‹¨ ì–´ë ¤ìš´ ê²½ìš°)
    # í˜„ì¬ëŠ” í™•ì¥ì ê¸°ë°˜ìœ¼ë¡œ ì¶©ë¶„í•˜ë¯€ë¡œ LLM ë¶„ì„ì€ ì„ íƒì ìœ¼ë¡œë§Œ ì‚¬ìš©
    # if llama and file_paths:
    #     ... (ì£¼ì„ ì²˜ë¦¬)

    # ê¸°ë³¸ê°’: ìƒì„± ëª¨ë“œ
    log.info(f"ğŸ¯ Mode detection: 'generate' (default)")
    return "generate"


def run_agent(file_paths=None, texts=None, max_steps: int = 10) -> Dict[str, Any]:
    """
    ReAct ì—ì´ì „íŠ¸ ì‹¤í–‰

    Args:
        file_paths: ì…ë ¥ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        texts: ì…ë ¥ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        max_steps: ìµœëŒ€ ì‹¤í–‰ ìŠ¤í…

    Returns:
        ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    state: Dict[str, Any] = {}

    # Llama ëª¨ë¸ ë¡œë“œ
    log.info("â”" + "â”"*78 + "â”“")
    log.info("â”ƒ ğŸ§  LOADING LLAMA MODEL")
    log.info("â”—" + "â”"*78 + "â”›")
    log.info(f"   Model: {LLAMA_MODEL_PATH}")
    log.info(f"   Context: {LLAMA_CTX}, Threads: {LLAMA_THREADS}")
    try:
        llama = ChatLlamaCpp(
            model_path=LLAMA_MODEL_PATH,
            n_ctx=LLAMA_CTX,
            n_threads=LLAMA_THREADS,
            temperature=0.0,
            max_tokens=LLAMA_MAX_TOKENS,
            verbose=False,
        )
        log.info("âœ… Llama model loaded successfully\n")
    except Exception as e:
        log.error(f"âŒ Failed to load Llama model: {e}")
        return {"ok": False, "error": str(e)}

    # ëª¨ë“œ ìë™ íŒë‹¨
    log.info("â”" + "â”"*78 + "â”“")
    log.info("â”ƒ ğŸ¯ MODE DETECTION")
    log.info("â”—" + "â”"*78 + "â”›")
    mode = _detect_mode(file_paths, texts, llama)
    state["mode"] = mode
    log.info(f"   Selected Mode: {mode.upper()}")
    log.info(f"   Files: {file_paths or []}")
    log.info(f"   Texts: {texts or []}\n")

    user_hint = {"file_paths": file_paths or [], "texts": texts or [], "mode": mode}
    history: List[HumanMessage] = [
        HumanMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=f"Inputs: {json.dumps(user_hint, ensure_ascii=False)}")
    ]

    for step in range(1, max_steps + 1):
        log.info(f"\n{'â”'*80}")
        log.info(f"ğŸ”„ STEP {step}/{max_steps}")
        log.info(f"{'â”'*80}")

        ai = llama.invoke(history)
        text = getattr(ai, "content", "")

        # Thought ì¶”ì¶œ ë° ì¶œë ¥
        thought_match = re.search(r"Thought:\s*(.+?)(?:\n|Action:|$)", text, flags=re.S)
        if thought_match:
            thought = thought_match.group(1).strip()
            log.info(f"ğŸ’­ THOUGHT: {thought}")

        # Action ì¶”ì¶œ ë° ì¶œë ¥
        action_match = re.search(r"Action:\s*(.*?)(?:\n\n|Observation:|$)", text, flags=re.S)
        if action_match:
            action = action_match.group(1).strip()
            log.info(f"âš¡ ACTION:\n{action}")

        # FinalAnswer ì²´í¬
        m_final = re.search(r"FinalAnswer:\s*(.+)", text, flags=re.S)
        if m_final and not _extract_tool_call(text):
            final_msg = m_final.group(1).strip()
            state["final_message"] = final_msg
            log.info(f"\n{'ğŸ¯'*40}")
            log.info(f"âœ… FINAL ANSWER: {final_msg}")
            log.info(f"{'ğŸ¯'*40}\n")
            break

        # ë„êµ¬ í˜¸ì¶œ ì¶”ì¶œ
        call = _extract_tool_call(text)
        if not call:
            # íŒíŠ¸ë¥¼ ê°•ì œë¡œ ì‹¤í–‰ (LLMì´ íŒë‹¨í•˜ì§€ ì•Šê³  ë°”ë¡œ ì‹¤í–‰)
            mode = state.get("mode", "generate")

            log.warning(f"âš ï¸  No tool call extracted, providing forced hint (step {step}, mode {mode})")

            # ê²€ì¦ ëª¨ë“œ ê°•ì œ ìˆœì„œ
            if mode == "validate":
                if step == 1:
                    # ì²« ë‹¨ê³„: ë¬´ì¡°ê±´ íŒŒì‹±
                    call = {
                        "tool": "parse_documents",
                        "args": {"file_paths": file_paths}
                    }
                    log.info(f"ğŸ”§ FORCED TOOL (step {step}): parse_documents")
                elif step == 2:
                    # ë‘ ë²ˆì§¸ ë‹¨ê³„: ë¬´ì¡°ê±´ ê²€ì¦ ë¦¬í¬íŠ¸
                    call = {
                        "tool": "generate_validation_report",
                        "args": {"output_format": "markdown", "output_dir": "output"}
                    }
                    log.info(f"ğŸ”§ FORCED TOOL (step {step}): generate_validation_report")
                else:
                    # 3ë‹¨ê³„ ì´ìƒì´ë©´ ì¢…ë£Œ
                    log.info(f"ğŸ”§ FORCED COMPLETION: All validation steps done (step {step})")
                    state["final_message"] = state.get("report_path", "Validation completed")
                    break

            # ìƒì„± ëª¨ë“œ ê°•ì œ ìˆœì„œ
            else:
                if step == 1 and file_paths:
                    # Excel/CSV íŒŒì¼ ì°¾ê¸°
                    excel_file = next((f for f in file_paths if f.endswith(('.xlsx', '.xls', '.csv'))), None)
                    if excel_file:
                        call = {
                            "tool": "generate_all_modules",
                            "args": {"excel_path": excel_file, "output_dir": "output"}
                        }
                        log.info(f"ğŸ”§ FORCED TOOL (step {step}): generate_all_modules")
                    else:
                        # Excel/CSVê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                        log.error(f"âŒ No Excel/CSV file found for generation mode")
                        state["final_message"] = "Error: No Excel/CSV file found"
                        break
                elif step == 2:
                    call = {"tool": "save_as_pdf", "args": {"output_dir": "output"}}
                    log.info(f"ğŸ”§ FORCED TOOL (step {step}): save_as_pdf")
                else:
                    # 3ë‹¨ê³„ ì´ìƒì´ë©´ ì¢…ë£Œ
                    log.info(f"ğŸ”§ FORCED COMPLETION: All generation steps done (step {step})")
                    state["final_message"] = state.get("pdf_path", "Generation completed")
                    break

            # LLMì—ê²Œë„ ì•Œë¦¼
            if call:
                history.append(HumanMessage(content=f"System: Executing forced action: {json.dumps(call, ensure_ascii=False)}"))
            # continue ëŒ€ì‹  callì„ ì§ì ‘ ì‹¤í–‰í•˜ë„ë¡ ì•„ë˜ë¡œ ì§„í–‰

        tool_name = call.get("tool")
        args = call.get("args") or {}
        tool_obj = TOOLS.get(tool_name)

        if not tool_obj:
            log.warning(f"âš ï¸  INVALID TOOL: '{tool_name}' - Available: {list(TOOLS.keys())}")
            history.append(HumanMessage(
                content=f"Observation: invalid tool '{tool_name}'. Available: {list(TOOLS.keys())}"
            ))
            continue

        # ë„êµ¬ ì‹¤í–‰
        log.info(f"ğŸ”§ EXECUTING TOOL: '{tool_name}'")
        log.info(f"   Args: {json.dumps(args, ensure_ascii=False, indent=2)}")
        try:
            result = _run_tool(tool_obj, args, state)
            log.info(f"âœ… TOOL SUCCESS: '{tool_name}' - Result: {result.get('ok', True)}")
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            if isinstance(result, dict):
                if 'error' not in result:
                    log.info(f"   ğŸ“Š Result summary: {str(result)[:200]}...")
        except Exception as e:
            result = {"ok": False, "error": str(e)}
            log.error(f"âŒ TOOL FAILED: '{tool_name}' - Error: {e}")

        # íŒŒì‹± ê²°ê³¼ë¥¼ stateì— ì €ì¥ (ê²€ì¦ì— í™œìš©)
        if tool_name == "parse_documents" and isinstance(result, dict) and result.get("ok"):
            parsed_text = ""
            for file_result in result.get("results", []):
                # Upstage íŒŒì‹± ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if "text" in file_result:
                    parsed_text += file_result["text"] + "\n\n"
                elif "content" in file_result:
                    parsed_text += file_result["content"] + "\n\n"

            state["parsed_content"] = parsed_text
            log.info(f"   ğŸ“„ Parsed content saved to state ({len(parsed_text)} chars)")

        # Observation ìƒì„± ë° ë¡œê¹…
        observation = f"Observation: {json.dumps(result, ensure_ascii=False)[:2000]}"
        log.info(f"ğŸ“ OBSERVATION: {observation[:500]}...")
        history.append(HumanMessage(content=observation))

        # ëª¨ë“œë³„ ì™„ë£Œ ì²˜ë¦¬
        mode = state.get("mode", "generate")

        if mode == "generate":
            # ìƒì„± ëª¨ë“œ: PDF ì €ì¥ ì™„ë£Œì‹œ ì¢…ë£Œ
            if tool_name == "save_as_pdf" and isinstance(result, dict) and result.get("ok"):
                state["pdf_path"] = result.get("path")
                state["pdf_size"] = result.get("size", 0)

                # Module 2 PDF ì •ë³´ë„ ì €ì¥
                if result.get("module2_path"):
                    state["module2_pdf_path"] = result.get("module2_path")
                    state["module2_pdf_size"] = result.get("module2_size", 0)

                log.info(f"\n{'ğŸ‰'*40}")
                log.info(f"âœ… CTD GENERATION COMPLETED")
                log.info(f"ğŸ“„ Complete PDF: {result.get('path')} ({result.get('size', 0):,} bytes)")
                if result.get("module2_path"):
                    log.info(f"ğŸ“„ Module 2 PDF: {result.get('module2_path')} ({result.get('module2_size', 0):,} bytes)")
                log.info(f"{'ğŸ‰'*40}\n")

                final_msg = f"PDF saved -> Complete: {result.get('path')}"
                if result.get("module2_path"):
                    final_msg += f" | Module2: {result.get('module2_path')}"
                history.append(HumanMessage(content=f"FinalAnswer: {final_msg}"))
                break

            # ëª¨ë“  ëª¨ë“ˆ ìƒì„± ì™„ë£Œì‹œ PDF ì €ì¥ íŒíŠ¸
            if tool_name == "generate_all_modules" and isinstance(result, dict) and result.get("ok"):
                state["modules_generated"] = result.get("modules", [])
                log.info(f"ğŸ“ Modules generated: {len(result.get('modules', []))} modules")

        else:  # validate ëª¨ë“œ
            # ê²€ì¦ ëª¨ë“œ: ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œì‹œ ì¢…ë£Œ
            if tool_name == "generate_validation_report" and isinstance(result, dict) and result.get("ok"):
                state["report_path"] = result.get("report_path")
                state["summary"] = result.get("summary", {})

                # ìŠ¤í‚¤ë§ˆ ì²´í¬ ì •ë³´ ì €ì¥ (ì›¹ UIì— ì „ë‹¬ìš©)
                if "schema_check" in result:
                    state["schema_check"] = result["schema_check"]

                summary_text = f"ê²€ì¦ ì™„ë£Œ: í†µê³¼ {result.get('summary', {}).get('passed', 0)}, ì‹¤íŒ¨ {result.get('summary', {}).get('failed', 0)}, ê²½ê³  {result.get('summary', {}).get('warnings', 0)}"
                log.info(f"\n{'ğŸ‰'*40}")
                log.info(f"âœ… VALIDATION COMPLETED")
                log.info(f"ğŸ“Š Summary: {summary_text}")
                log.info(f"ğŸ“„ Report: {result.get('report_path')}")
                if "schema_check" in result:
                    schema_check = result["schema_check"]
                    log.info(f"ğŸ“‹ ICH Schema: {schema_check.get('found', 0)}/{schema_check.get('total_required', 0)} items found")
                log.info(f"{'ğŸ‰'*40}\n")
                history.append(HumanMessage(content=f"FinalAnswer: {summary_text} | Report -> {result.get('report_path')}"))
                break

    return state


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    result = run_agent(texts=["ë‹¹ë‡¨ë³‘ ê³ í˜ˆì•• ì¹˜ë£Œ"])
    print("\n" + "="*70)
    print("Agent Result:", result.get("final_message", "No final message"))
    print("="*70)
